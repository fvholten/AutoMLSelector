{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the trainings data-script\n",
    "\n",
    "#### Read datasets from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "dataset_ids = []\n",
    "dataset_id_tool_dict = {}\n",
    "automltools = set()\n",
    "\n",
    "with open('assets/openml-datasets.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "\n",
    "    index = 0\n",
    "    best_tool = 0\n",
    "    for line in csv_reader:\n",
    "      if index == 0:\n",
    "        best_tool = len(line)-1\n",
    "\n",
    "      if index != 0 and len(line) != 0:\n",
    "        dataset_ids.append(line[0])\n",
    "        dataset_id_tool_dict[int(line[0])] = line[best_tool].split('/')\n",
    "\n",
    "        automltools |= set(line[best_tool].split('/'))\n",
    "\n",
    "      index =+ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets with Ids from AutoML.org (Python API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml as oml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = oml.datasets.get_datasets(dataset_ids)\n",
    "list_qualities = oml.datasets.list_qualities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save qualities to `_meta.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../app/_meta.csv', 'w') as csv_file:\n",
    "  wr = csv.writer(csv_file, quoting=csv.QUOTE_MINIMAL)\n",
    "  wr.writerow(['Field_Name'])\n",
    "  for q in list_qualities:\n",
    "    wr.writerow([q])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training-data's in `training-data/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml, csv\n",
    "\n",
    "# the openml dataset ids for all 97 datasets\n",
    "dataset_ids = [...]\n",
    "# a dictonary mapping the dataset ids to a list of all tools that performed best on this dataset\n",
    "dataset_id_tool_dict = dict(...)\n",
    "# loads the qualities \n",
    "list_qualities = openml.datasets.list_qualities()\n",
    "# iterate over each automl tool\n",
    "for automltool in automltools:\n",
    "  # create a csv file that then contains the training data\n",
    "  with open('training-data/' + automltool + '-data.csv', 'w') as csv_file:\n",
    "    wr = csv.writer(csv_file, quoting=csv.QUOTE_MINIMAL)\n",
    "    # the first line of the training data describes the independent features (qualities) and the destination feature: automltool\n",
    "    wr.writerow(list_qualities + [automltool])\n",
    "    # iterate over each dataset and create a csv entry for each, containing the independend features and the destination feature (if the automltool was best)\n",
    "    for dataset in openml.datasets.get_datasets(dataset_ids):\n",
    "     wr.writerow(list(map(lambda quality: dataset.qualities.get(quality), list_qualities)) + [int(automltool in dataset_id_tool_dict.get(dataset.dataset_id))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
